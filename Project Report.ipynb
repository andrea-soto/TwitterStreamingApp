{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Streaming Application\n",
    "\n",
    "**Andrea Soto | Exercise 2 | MIDS W205 - Storing and Retrieving Data**\n",
    "\n",
    "---\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this exercise I developed an application that reads a stream of tweets from the Twitter API, parses the tweets to count the number of occurrences of each word in the stream of tweets, and writes the final results to a Postgres database.\n",
    "\n",
    "The architecture is shown in the image below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Architecture](./architecture.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The directory structure of the project is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".\r\n",
      "|-- Develop Code.ipynb\r\n",
      "|-- EX2Tweetwordcount\r\n",
      "|   |-- config.json\r\n",
      "|   |-- dev-resources\r\n",
      "|   |-- fabfile.py\r\n",
      "|   |-- logs\r\n",
      "|   |-- project.clj\r\n",
      "|   |-- src\r\n",
      "|   |   |-- bolts\r\n",
      "|   |   |   |-- __init__.py\r\n",
      "|   |   |   |-- parse.py\r\n",
      "|   |   |   `-- wordcount.py\r\n",
      "|   |   `-- spouts\r\n",
      "|   |       |-- __init__.py\r\n",
      "|   |       `-- tweets.py\r\n",
      "|   |-- tasks.py\r\n",
      "|   |-- test\r\n",
      "|   |-- topologies\r\n",
      "|   |   `-- tweetwordcount.clj\r\n",
      "|   `-- virtualenvs\r\n",
      "|       `-- wordcount.txt\r\n",
      "|-- Project Report.ipynb\r\n",
      "|-- README.md\r\n",
      "|-- analysis\r\n",
      "|   |-- finalresults.py\r\n",
      "|   |-- histogram.py\r\n",
      "|   |-- plot.png\r\n",
      "|   `-- top20.py\r\n",
      "|-- architecture.png\r\n",
      "|-- logo.png\r\n",
      "`-- screenshots\r\n",
      "    |-- screenshot_1-Test Twitter Connection.png\r\n",
      "    |-- screenshot_2-Check Adding Records To Postgres.png\r\n",
      "    |-- screenshot_3-Running Application.png\r\n",
      "    `-- screenshot_4-Storm Topology.png\r\n",
      "\r\n",
      "11 directories, 24 files\r\n"
     ]
    }
   ],
   "source": [
    "!tree -I 'streamparse_tweetwordcount*|_build*|_resources'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "table {float:left}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<style>\n",
    "table {float:left}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "The main directories of the project are:\n",
    "\n",
    "- **EX2Tweetwordcount:** Location of the storm project where the spouts, bolts, and topology scripts reside\n",
    "- **analysis:** Location of the python servicing scripts that query the Postgres database\n",
    "- **screenshots:** Location of the three screen-shots that show the end-to-end execution of the application\n",
    "\n",
    "The description of the main files of the project and their location are shown in the tables below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Storm Application Files\n",
    "|File Name|Location|Description|\n",
    "|:--|:--|:--|\n",
    "|tweetwordcount.clj  |./EX2Tweetwordcount/topologies/|Application topology|\n",
    "|tweets.py|./EX2Tweetwordcount/src/spouts/|Spout to collect tweets|\n",
    "|parse.py|./EX2Tweetwordcount/src/bolts/|Bolt to parse tweet and clean words|\n",
    "|wordcount.py|./EX2Tweetwordcount/src/bolts/|Bolt to count words and update Postgres|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Servicing Files (Query Postgres Database)\n",
    "|File Name|Location|Description|\n",
    "|:--|:--|:--|\n",
    "|finalresults.py|./analysis/|Return the count of a word. If a word is not provided, it returns all word counts|\n",
    "|histogram.py|./analysis/|Return all words with count between a given interval|\n",
    "|top20.py|./analysis/|Return the top-20 words by count and create a bar-chart saved as 'plot.png'|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Streaming Overview\n",
    "\n",
    "The following commands were used to run the storm application and collect tweets:\n",
    "\n",
    "> `cd EX2Tweetwordcount`  \n",
    "\n",
    "> `sparse run`\n",
    "\n",
    "Tweets were collected for approximately one day starting December 3 and ending December 4. The number of distinct words encountered and the total count of all words is shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of distinct words:\t61,569\n",
      "Total count of all words:\t3,702,525\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import sys\n",
    "\n",
    "conn = psycopg2.connect(database=\"tcount\", user=\"postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "summary = []\n",
    "sql = \"select count(*) from Tweetwordcount ;\" \n",
    "cur.execute(sql)\n",
    "summary.append(('Number of distinct words:\\t', cur.fetchall()[0][0]))\n",
    "\n",
    "sql = \"select sum(count) from Tweetwordcount ;\" \n",
    "cur.execute(sql)\n",
    "summary.append(('Total count of all words:\\t', cur.fetchall()[0][0]))\n",
    "\n",
    "conn.commit()\n",
    "conn.close()\n",
    "\n",
    "for i,j in summary:\n",
    "    print i+\"{:,}\".format(j)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Servicing scripts\n",
    "\n",
    "This section describes how to use the three servicing scripts. The following descriptions assumed the scripts are runned from the main project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# finalresults.py\n",
    "\n",
    "Given a word, return the total number of occurrences of the word in the stream. \n",
    "\n",
    "If a word is not provided, it returns all the word counts in alphabetical order. Since there are over 60,000 words, the outpt is limited to the first N word counts. The parameter N can be sent as an input, with the default being 25 words.\n",
    "\n",
    "**USAGE**\n",
    "\n",
    "To get the number of occurances of a single word:  \n",
    "> `python analysis/finalresults.py hello`\n",
    "    \n",
    "Get all the word counts, sorted alphabetically, one per line:\n",
    "> `python analysis/finalresults.py`\n",
    "    \n",
    "By default, only the first 25 words are printed to the console. The number of words shown can be increased by sending an integer as a parameter. The example below would show the first 500 words.\n",
    "> `python analysis/finalresults.py 500`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Output of `finalresults.py`\n",
    "\n",
    "The following examples show queries while the stream application was running and after the applicaiton was terminated. \n",
    "\n",
    "The queries done while the application was running were used to make sure the application was running properly and that the counts were increasing. It was interesting to see how the words in the results change over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query all words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 word-counts (out of 777 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "           a  63\r\n",
      "        able  2\r\n",
      "       about  7\r\n",
      "   according  1\r\n",
      "     account  2\r\n",
      "    actually  3\r\n",
      "     address  3\r\n",
      "       adele  1\r\n",
      "      adidas  2\r\n",
      "       after  1\r\n"
     ]
    }
   ],
   "source": [
    "# Query at the beginning of tweet collection\n",
    "!python analysis/finalresults.py 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 word-counts (out of 10059 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "           a  4168\r\n",
      "      aaaaah  2\r\n",
      "      aaaand  2\r\n",
      "       aampa  2\r\n",
      "       aampp  2\r\n",
      "       aaood  2\r\n",
      "       aaron  2\r\n",
      "      aatuit  2\r\n",
      "          ab  12\r\n",
      "     abandon  2\r\n"
     ]
    }
   ],
   "source": [
    "# Query after some time had pass\n",
    "!python analysis/finalresults.py 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 word-counts (out of 61569 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "           `  1\r\n",
      "           a  97611\r\n",
      "          aa  31\r\n",
      "         aaa  12\r\n",
      "        aaaa  4\r\n",
      "       aaaaa  2\r\n",
      "      aaaaaa  5\r\n",
      "  aaaaaaaaaa  2\r\n",
      " aaaaaaaaaaa  1\r\n",
      "aaaaaaaaaaaaaaahhhhh  2\r\n"
     ]
    }
   ],
   "source": [
    "# Query at the end of tweet collection\n",
    "!python analysis/finalresults.py 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Query word 'the' at different moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of 'the':  4585 \t@ Thu Dec  3 03:37:58 2015\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/finalresults.py the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of 'the':  60769 \t@ Thu Dec  3 05:16:51 2015\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/finalresults.py the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of 'the':  150201 \t@ Fri Dec  4 03:06:11 2015\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/finalresults.py the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of 'the':  150201 \t@ Fri Dec 11 19:46:25 2015\r\n"
     ]
    }
   ],
   "source": [
    "# Final count of 'the'\n",
    "!python analysis/finalresults.py the"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# histogram.py\n",
    "\n",
    "Given an interval defined by two integers k1 and k2, return all the words that have a count between the interval (including interval limits).\n",
    "\n",
    "**USAGE**\n",
    "\n",
    "To get all the words with a frequency between 1500 and 2000:  \n",
    "> `python analysis/histogram.py 1500 2000`\n",
    "\n",
    "By default, only the first 25 words are printed to the console. The number of words shown can be increased by sending a third integer as a parameter. The example below would show the first 50 words.\n",
    "> `python analysis/histogram.py 1500 2000 50`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample Output of histogram.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporting 5 words (out of 5 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "         our  1040\r\n",
      "         her  1047\r\n",
      "      weeknd  1070\r\n",
      "       would  1072\r\n",
      "        back  1087\r\n"
     ]
    }
   ],
   "source": [
    "# Query while stream application was running\n",
    "!python analysis/histogram.py 1000 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporting 25 words (out of 32 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "relationship  1002\r\n",
      "      chance  1005\r\n",
      "       smile  1007\r\n",
      "        fans  1008\r\n",
      "          yo  1009\r\n",
      "        asks  1010\r\n",
      "         far  1020\r\n",
      "     answers  1020\r\n",
      "       media  1026\r\n",
      "        full  1026\r\n",
      "        gone  1031\r\n",
      "        mama  1031\r\n",
      "        must  1034\r\n",
      "     prayers  1035\r\n",
      "        past  1042\r\n",
      "        turn  1042\r\n",
      "         wow  1044\r\n",
      "       hours  1045\r\n",
      "    probably  1046\r\n",
      "       story  1048\r\n",
      "        fall  1049\r\n",
      "      havent  1051\r\n",
      "       least  1064\r\n",
      "           s  1069\r\n",
      "    violence  1082\r\n"
     ]
    }
   ],
   "source": [
    "# Query after termination\n",
    "!python analysis/histogram.py 1000 1100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reporting 30 words (out of 32 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "relationship  1002\r\n",
      "      chance  1005\r\n",
      "       smile  1007\r\n",
      "        fans  1008\r\n",
      "          yo  1009\r\n",
      "        asks  1010\r\n",
      "         far  1020\r\n",
      "     answers  1020\r\n",
      "       media  1026\r\n",
      "        full  1026\r\n",
      "        gone  1031\r\n",
      "        mama  1031\r\n",
      "        must  1034\r\n",
      "     prayers  1035\r\n",
      "        past  1042\r\n",
      "        turn  1042\r\n",
      "         wow  1044\r\n",
      "       hours  1045\r\n",
      "    probably  1046\r\n",
      "       story  1048\r\n",
      "        fall  1049\r\n",
      "      havent  1051\r\n",
      "       least  1064\r\n",
      "           s  1069\r\n",
      "    violence  1082\r\n",
      "         top  1082\r\n",
      "        goes  1083\r\n",
      "          vs  1086\r\n",
      "        rest  1087\r\n",
      "        true  1092\r\n"
     ]
    }
   ],
   "source": [
    "# Increase words shown to 30\n",
    "!python analysis/histogram.py 1000 1100 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# top20.py\n",
    "\n",
    "This script finds the top-20 words by count.\n",
    "\n",
    "It prints the words to the console and creates a bar-chart called `plot.png` in the directory where the script is called. If plot.png already exitst, the file will be overwritten.\n",
    "\n",
    "In the example below, the script was run from the project directory. The file `plot.png` was then moved to the analysis folder.\n",
    "\n",
    "**USAGE**\n",
    "\n",
    "To get the top-20 words by count:  \n",
    "> `python analysis/top20.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20\r\n",
      "ID     Word  Count\r\n",
      " 1       the  150201\r\n",
      " 2         i  122672\r\n",
      " 3       you  99256\r\n",
      " 4         a  97611\r\n",
      " 5        to  88872\r\n",
      " 6       and  51924\r\n",
      " 7        in  48953\r\n",
      " 8        of  47513\r\n",
      " 9        is  44492\r\n",
      "10       for  42390\r\n",
      "11        my  34410\r\n",
      "12      this  30196\r\n",
      "13        on  29920\r\n",
      "14        me  29550\r\n",
      "15        it  28681\r\n",
      "16        im  27679\r\n",
      "17      that  27270\r\n",
      "18        be  24402\r\n",
      "19      when  23132\r\n",
      "20        so  22948\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/top20.py\n",
    "!mv plot.png analysis/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Top20 Words](analysis/plot.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
