{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "import time\n",
    "import sys\n",
    "   \n",
    "conn = psycopg2.connect(database=\"tcount\", user=\"postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "sql = \"delete from Tweetwordcount ;\" \n",
    "cur.execute(sql)\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(20079L,)]\n"
     ]
    }
   ],
   "source": [
    "conn = psycopg2.connect(database=\"tcount\", user=\"postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "sql = \"select count(*) from Tweetwordcount ;\" \n",
    "cur.execute(sql)\n",
    "print cur.fetchall()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conn = psycopg2.connect(database=\"tcount\", user=\"postgres\")\n",
    "cur = conn.cursor()\n",
    "\n",
    "word = 'andreasoto'\n",
    "sql = \"SELECT * FROM Tweetwordcount WHERE word='%s';\" %(word)\n",
    "cur.execute(sql)\n",
    "test = cur.fetchall()\n",
    "conn.commit()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Serving Scripts\n",
    "\n",
    "## finalresults.py\n",
    "\n",
    "This script gets a word as an argument and returns the total number of word occurrences in the stream. This script can also be used to query all the word counts, order them alphabetically, and report the first N word counts. The default N is 25, but this number can be sent as an input.\n",
    "\n",
    "**USAGE**\n",
    "\n",
    "To get the number of occurances of a single word:  \n",
    "> `python finalresults.py hello`\n",
    "    \n",
    "Get all the word counts, sorted alphabetically, one per line:\n",
    "> `python finalresults.py`\n",
    "    \n",
    "The default is to show only the first 25 words. To increase the number of words shown, send the number of records to show as an input:\n",
    "> `python finalresults.py 2000`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting analysis/finalresults.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile analysis/finalresults.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import psycopg2\n",
    "import time\n",
    "import sys\n",
    "   \n",
    "def get_wordCount(word, show=25):\n",
    "    # Get count for the input word or all word counts. \n",
    "    # The output is restricted to the 'show' value.\n",
    "    \n",
    "    # Connect to database\n",
    "    conn = psycopg2.connect(database=\"tcount\", user=\"postgres\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Get total words counted in tweets\n",
    "    sql = \"SELECT count(*) FROM Tweetwordcount ;\" \n",
    "    cur.execute(sql)\n",
    "    total_words = cur.fetchall()\n",
    "    conn.commit()\n",
    "    \n",
    "    # Get count for word or all words (depending on input)\n",
    "    if word == None:\n",
    "        sql = \"SELECT * FROM Tweetwordcount ORDER BY word ASC LIMIT %d;\"%(min(show,total_words[0][0]))        \n",
    "    else:\n",
    "        sql = \"SELECT * FROM Tweetwordcount WHERE word='%s';\" %(word)\n",
    "    \n",
    "    cur.execute(sql)\n",
    "    result = cur.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    # Print results\n",
    "    if word == None:\n",
    "        print 'First %d word-counts (out of %d words):\\n'%(min(show,total_words[0][0]),total_words[0][0])\n",
    "        print \"%12s  %s\"%('Word','Count')\n",
    "        for w,c in result:\n",
    "            print \"%12s  %d\"%(w,c)\n",
    "    else:\n",
    "        print \"Number of occurences of '%s':  %d\"%(result[0][0], result[0][1]), \"\\t@\", time.ctime(time.time())\n",
    "\n",
    "# ===================================================================================\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    To get the number of occurances of single word:\n",
    "       python finalresults.py hello\n",
    "    \n",
    "    Get all the word counts, sorted alphabetically, one per line:\n",
    "       python finalresults.py\n",
    "    \n",
    "    The default is to show only the first 25 words. \n",
    "    To increase the number of words shown, send any number as an input:\n",
    "       python finalresults.py 2000\n",
    "    '''    \n",
    "    \n",
    "    numToShow = 25\n",
    "    word = None\n",
    "    # Get input word if any\n",
    "    if len(sys.argv) > 1:\n",
    "        # Get target word\n",
    "        if sys.argv[1].isdigit():\n",
    "            numToShow = int(sys.argv[1])\n",
    "        else:\n",
    "            word = sys.argv[1]\n",
    "    \n",
    "    get_wordCount(word, numToShow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 word-counts (out of 777 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "           a  63\r\n",
      "        able  2\r\n",
      "       about  7\r\n",
      "   according  1\r\n",
      "     account  2\r\n",
      "    actually  3\r\n",
      "     address  3\r\n",
      "       adele  1\r\n",
      "      adidas  2\r\n",
      "       after  1\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/finalresults.py 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of 'the':  174 \t@ Thu Dec  3 01:23:13 2015\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/finalresults.py the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of 'the':  20624 \t@ Thu Dec  3 02:14:29 2015\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/finalresults.py the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of occurences of 'the':  49 \t@ Thu Dec  3 02:15:14 2015\r\n"
     ]
    }
   ],
   "source": [
    "!python analysis/finalresults.py the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 word-counts (out of 5294 words):\r\n",
      "\r\n",
      "        Word  Count\r\n",
      "           a  1392\r\n",
      "         aaa  2\r\n",
      "       aaaaa  2\r\n",
      "       aaand  2\r\n",
      "         aap  2\r\n",
      "         aba  2\r\n",
      "         abc  2\r\n",
      "   abductors  2\r\n",
      "     abiding  2\r\n",
      "     ability  4\r\n"
     ]
    }
   ],
   "source": [
    "!python finalresults.py 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## histogram.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%writefile analysis/histogram.py\n",
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "import psycopg2\n",
    "import time\n",
    "import sys\n",
    "   \n",
    "def get_wordCount(word, show=25):\n",
    "    # Get count for the input word or all word counts. \n",
    "    # The output is restricted to the 'show' value.\n",
    "    \n",
    "    # Connect to database\n",
    "    conn = psycopg2.connect(database=\"tcount\", user=\"postgres\")\n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    # Get total words counted in tweets\n",
    "    sql = \"SELECT count(*) FROM Tweetwordcount ;\" \n",
    "    cur.execute(sql)\n",
    "    total_words = cur.fetchall()\n",
    "    conn.commit()\n",
    "    \n",
    "    # Get count for word or all words (depending on input)\n",
    "    if word == None:\n",
    "        sql = \"SELECT * FROM Tweetwordcount ORDER BY word ASC LIMIT %d;\"%(min(show,total_words[0][0]))        \n",
    "    else:\n",
    "        sql = \"SELECT * FROM Tweetwordcount WHERE word='%s';\" %(word)\n",
    "    \n",
    "    cur.execute(sql)\n",
    "    result = cur.fetchall()\n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    \n",
    "    # Print results\n",
    "    if word == None:\n",
    "        print 'First %d word-counts (out of %d words):\\n'%(min(show,total_words[0][0]),total_words[0][0])\n",
    "        print \"%12s  %s\"%('Word','Count')\n",
    "        for w,c in result:\n",
    "            print \"%12s  %d\"%(w,c)\n",
    "    else:\n",
    "        print \"Number of occurences of '%s':  %d\"%(result[0][0], result[0][1]), \"\\t@\", time.ctime(time.time())\n",
    "\n",
    "# ===================================================================================\n",
    "if __name__ == '__main__':\n",
    "    '''\n",
    "    To get the number of occurances of single word:\n",
    "       python finalresults.py hello\n",
    "    \n",
    "    Get all the word counts, sorted alphabetically, one per line:\n",
    "       python finalresults.py\n",
    "    \n",
    "    The default is to show only the first 25 words. \n",
    "    To increase the number of words shown, send any number as an input:\n",
    "       python finalresults.py 2000\n",
    "    '''    \n",
    "    \n",
    "    numToShow = 25\n",
    "    word = None\n",
    "    # Get input word if any\n",
    "    if len(sys.argv) > 1:\n",
    "        # Get target word\n",
    "        if sys.argv[1].isdigit():\n",
    "            numToShow = int(sys.argv[1])\n",
    "        else:\n",
    "            word = sys.argv[1]\n",
    "    \n",
    "    get_wordCount(word, numToShow)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Spout: tweet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/spouts/tweets.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/spouts/tweets.py\n",
    "from __future__ import absolute_import, print_function, unicode_literals\n",
    "#TEST THIS\n",
    "import itertools, time\n",
    "import tweepy, copy \n",
    "import Queue, threading\n",
    "\n",
    "from streamparse.spout import Spout\n",
    "\n",
    "################################################################################\n",
    "# Twitter credentials\n",
    "################################################################################\n",
    "twitter_credentials = {\n",
    "    \"consumer_key\"        :  \"lxm4Nf8lJElAi5VCvbCTAeSj1\",\n",
    "    \"consumer_secret\"     :  \"KKWw60hoRLU3TOkiHtT2xLOTu3G3bcQ6eee9kbZPahfxVDiB3F\",\n",
    "    \"access_token\"        :  \"195097748-N9FbGLe2H32RPzMy9upSbflkk7GisamQ0XFt76Rg\",\n",
    "    \"access_token_secret\" :  \"4aiLQlyUkeFnJ2Dhw5FS9TZn2oHLdqsivH7YKXRwnBkGj\"\n",
    "}\n",
    "\n",
    "def auth_get(auth_key):\n",
    "    if auth_key in twitter_credentials:\n",
    "        return twitter_credentials[auth_key]\n",
    "    return None\n",
    "\n",
    "################################################################################\n",
    "# Class to listen and act on the incoming tweets\n",
    "################################################################################\n",
    "class TweetStreamListener(tweepy.StreamListener):\n",
    "\n",
    "    def __init__(self, listener):\n",
    "        self.listener = listener\n",
    "        super(self.__class__, self).__init__(listener.tweepy_api())\n",
    "\n",
    "    def on_status(self, status):\n",
    "        self.listener.queue().put(status.text, timeout = 0.01)\n",
    "        return True\n",
    "  \n",
    "    def on_error(self, status_code):\n",
    "        return True # keep stream alive\n",
    "  \n",
    "    def on_limit(self, track):\n",
    "        return True # keep stream alive\n",
    "\n",
    "class Tweets(Spout):\n",
    "\n",
    "    def initialize(self, stormconf, context):\n",
    "        self._queue = Queue.Queue(maxsize = 100)\n",
    "\n",
    "        consumer_key = auth_get(\"consumer_key\") \n",
    "        consumer_secret = auth_get(\"consumer_secret\") \n",
    "        auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "\n",
    "        if auth_get(\"access_token\") and auth_get(\"access_token_secret\"):\n",
    "            access_token = auth_get(\"access_token\")\n",
    "            access_token_secret = auth_get(\"access_token_secret\")\n",
    "            auth.set_access_token(access_token, access_token_secret)\n",
    "\n",
    "        self._tweepy_api = tweepy.API(auth)\n",
    "\n",
    "        # Create the listener for twitter stream\n",
    "        listener = TweetStreamListener(self)\n",
    "\n",
    "        # Create the stream and listen for english tweets\n",
    "        stream = tweepy.Stream(auth, listener, timeout=None)\n",
    "        stream.filter(languages=[\"en\"], track=[\"a\", \"the\", \"i\", \"you\", \"u\"], async=True)\n",
    "\n",
    "    def queue(self):\n",
    "        return self._queue\n",
    "\n",
    "    def tweepy_api(self):\n",
    "        return self._tweepy_api\n",
    "\n",
    "    def next_tuple(self):\n",
    "        try:\n",
    "            tweet = self.queue().get(timeout = 0.1) \n",
    "            if tweet:\n",
    "                self.queue().task_done()\n",
    "                self.emit([tweet])\n",
    " \n",
    "        except Queue.Empty:\n",
    "            self.log(\"Empty queue exception\")\n",
    "            time.sleep(0.1) \n",
    "\n",
    "    def ack(self, tup_id):\n",
    "        pass  # if a tuple is processed properly, do nothing\n",
    "\n",
    "    def fail(self, tup_id):\n",
    "        pass  # if a tuple fails to process, do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bolt: parse.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/bolts/parse.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/bolts/parse.py \n",
    "from __future__ import absolute_import, print_function, unicode_literals\n",
    "\n",
    "import re\n",
    "from streamparse.bolt import Bolt\n",
    "\n",
    "################################################################################\n",
    "# Function to check if the string contains only ascii chars\n",
    "################################################################################\n",
    "def ascii_string(s):\n",
    "    return all(ord(c) < 128 for c in s)\n",
    "\n",
    "class ParseTweet(Bolt):\n",
    "\n",
    "    def process(self, tup):\n",
    "        tweet = tup.values[0]  # extract the tweet\n",
    "\n",
    "        # Split the tweet into words\n",
    "        words = tweet.split()\n",
    "\n",
    "        # Filter out the hash tags, RT, @ and urls\n",
    "        valid_words = []\n",
    "        for word in words:\n",
    "\n",
    "            # Filter the hash tags\n",
    "            if word.startswith(\"#\"): continue\n",
    "\n",
    "            # Filter the user mentions\n",
    "            if word.startswith(\"@\"): continue\n",
    "\n",
    "            # Filter out retweet tags\n",
    "            if word.startswith(\"RT\"): continue\n",
    "\n",
    "            # Filter out the urls\n",
    "            if word.startswith(\"http\"): continue\n",
    "\n",
    "            # Strip leading and lagging punctuations\n",
    "            aword = word.strip(\"\\\"?><,'.:;)\")\n",
    "            # Clean other charactes from string \n",
    "            aword = aword.lower()\n",
    "            # Basic word cleaning\n",
    "            aword = re.sub(\"'\",\"\",aword)\n",
    "            aword = re.sub(\"/\",\"\", aword)\n",
    "            aword = re.sub(\"\\)\",\"\", aword)\n",
    "            aword = re.sub(\"\\(\",\"\", aword)\n",
    "            aword = re.sub(\"[0-9!@#$%^&*-_+=~{}|:;<>?,.]\",\"\", aword)\n",
    "            aword = aword.replace(\"\\\\\",\"\")\n",
    "\n",
    "            # now check if the word contains only ascii\n",
    "            if len(aword) > 0 and ascii_string(word):\n",
    "                valid_words.append([aword])\n",
    "\n",
    "        if not valid_words: return\n",
    "\n",
    "        # Emit all the words\n",
    "        self.emit_many(valid_words)\n",
    "\n",
    "        # tuple acknowledgement is handled automatically"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bolt: wordcount.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting src/bolts/wordcount.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile src/bolts/wordcount.py\n",
    "from __future__ import absolute_import, print_function, unicode_literals\n",
    "\n",
    "from collections import Counter\n",
    "from redis import StrictRedis\n",
    "from streamparse.bolt import Bolt\n",
    "\n",
    "import psycopg2\n",
    "import time\n",
    "\n",
    "class WordCounter(Bolt):\n",
    "\n",
    "    def initialize(self, conf, ctx):\n",
    "        self.counts = Counter()\n",
    "        self.redis = StrictRedis()\n",
    "\n",
    "    def process(self, tup):\n",
    "        word = tup.values[0]\n",
    "\n",
    "        # Write codes to increment the word count in Postgres\n",
    "        # Use psycopg to interact with Postgres\n",
    "        # Database name: Tcount \n",
    "        # Table name: Tweetwordcount \n",
    "        \n",
    "        # Connect to database\n",
    "        conn = psycopg2.connect(database=\"tcount\", user=\"postgres\")\n",
    "        cur = conn.cursor()\n",
    "        \n",
    "        # Increment the local count\n",
    "        self.counts[word] += 1\n",
    "        \n",
    "        # Check if word is already in the table \n",
    "        # (to stop and restart stream process without overwriting current table or deleting it)\n",
    "        sql = \"SELECT * FROM Tweetwordcount WHERE word='%s';\" %(word)\n",
    "        cur.execute(sql)\n",
    "        has_word = cur.fetchall()\n",
    "        conn.commit()\n",
    "        \n",
    "        if len(has_word) == 0:\n",
    "            # New word > INSERT INTO\n",
    "            sql = \"INSERT INTO Tweetwordcount (word,count) VALUES ('%s', %d);\" %(unicode(word), self.counts[word])\n",
    "        else:\n",
    "            # Update word count > UPDATE\n",
    "            sql = \"UPDATE Tweetwordcount SET count=%d WHERE word='%s';\" %(self.counts[word], unicode(word))\n",
    "\n",
    "        cur.execute(sql)\n",
    "        conn.commit()\n",
    "        #self.emit([word, self.counts[word]])\n",
    "\n",
    "        # Log the count - just to see the topology running\n",
    "        self.log('%s: %d' % (word, self.counts[word]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
